{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "import urllib3\n",
    "\n",
    "# Disabilita gli avvisi di HTTPS non verificato\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "# Ignora i FutureWarning\n",
    "warnings.simplefilter(action=\"ignore\", category=FutureWarning)\n",
    "from playsound import playsound\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "informazioni_geografiche = pd.read_csv(\"informazioni_geografiche.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raccolta(comune, pagina_del_comune):\n",
    "    df_dic = {}\n",
    "\n",
    "    def pulisci_dataframe(data_dict, colonne_da_rinominare):\n",
    "        \"\"\"\n",
    "        Pulisce un DataFrame disordinato, aggiungendo automaticamente la prima riga \n",
    "        e rinominando le colonne specificate.\n",
    "\n",
    "        :param data_dict: Dizionario dei dati grezzi\n",
    "        :param colonne_da_rinominare: Lista di nomi per le colonne finali\n",
    "        :return: DataFrame pulito\n",
    "        \"\"\"\n",
    "        \n",
    "        # Convertiamo il dizionario in un DataFrame temporaneo\n",
    "        df_temp = pd.DataFrame(data_dict)\n",
    "\n",
    "        # Recuperiamo automaticamente la prima riga (nomi effettivi delle colonne)\n",
    "        prima_riga = [col.replace(\":\", \"\").strip() for col in df_temp.columns[:len(colonne_da_rinominare)]]\n",
    "        \n",
    "        # Creiamo un nuovo DataFrame con la prima riga inclusa\n",
    "        df_clean = pd.DataFrame({\n",
    "            colonne_da_rinominare[i]: [prima_riga[i]] + df_temp.iloc[:, i].str.replace(\":\", \"\").str.strip().tolist()\n",
    "            for i in range(len(colonne_da_rinominare))\n",
    "        })\n",
    "\n",
    "        # Pulizia e conversione dei numeri\n",
    "        for col in df_clean.columns:\n",
    "            if col == \"Percentuale_Totale\": #.str.contains(\"%\").any():  # Se contiene percentuali\n",
    "                df_clean[col] = df_clean[col].str.replace(\",\", \".\").str.rstrip(\"%\").astype(float) / 10\n",
    "            elif df_clean[col].str.replace(\".\", \"\", regex=False).str.isnumeric().all():  # Se √® un numero\n",
    "                df_clean[col] = df_clean[col].str.replace(\".\", \"\", regex=False).astype(int)  # Rimuove i punti\n",
    "\n",
    "        return df_clean\n",
    "\n",
    "    def transform_dict_to_df(data_dict):\n",
    "        df = pd.DataFrame(data_dict)\n",
    "        new_data = {}\n",
    "\n",
    "        for col in df.columns:\n",
    "            if col != list(data_dict.keys())[0]:  \n",
    "                for idx, age_group in df[list(data_dict.keys())[0]].items():\n",
    "                    new_col_name = f\"{col}_{age_group}\"\n",
    "                    new_data[new_col_name] = df.at[idx, col]  # Aggiungiamo il valore corrispondente\n",
    "\n",
    "        # Creiamo il nuovo DataFrame con una sola riga\n",
    "        new_df = pd.DataFrame([new_data])\n",
    "        \n",
    "        return new_df\n",
    "\n",
    "    def concat_dataframe(accesso, df2):\n",
    "        df1 = pd.read_csv(accesso)\n",
    "        df = pd.concat([df1, df2], ignore_index=True)\n",
    "        df.to_csv(accesso, index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    # Trova il paragrafo con le informazioni\n",
    "    dati_paragrafo = pagina_del_comune.find(\"p\", class_=\"well\")\n",
    "\n",
    "    if dati_paragrafo:\n",
    "        testo = dati_paragrafo.get_text()\n",
    "\n",
    "        # Estrai le informazioni con slicing testuale\n",
    "        info = {}\n",
    "        info[\"Municipio\"] = testo.split(\"Municipio: \")[1].split(\",\")[0]\n",
    "        info[\"Provincia\"] = testo.split(\"Provincia: \")[1].split(\".\")[0]\n",
    "        info[\"Distanza dal capoluogo\"] = testo.split(\"Distanza dal capoluogo\")[1].split(\": \")[1].split(\" \")[0] + \" Km\"\n",
    "        info[\"Abitanti\"] = testo.split(\"Abitanti: \")[1].split(\" \")[0]\n",
    "        info[\"Denominazione\"] = testo.split(\"Denominazione: \")[1].split(\".\")[0]\n",
    "\n",
    "        # Stampare il risultato\n",
    "        for k, v in info.items():\n",
    "            df_dic[k] = v\n",
    "\n",
    "    else:\n",
    "        print(\"Errore: Impossibile trovare il paragrafo con i dati richiesti.\")\n",
    "\n",
    "    # Trova il paragrafo che contiene la densit√† abitativa\n",
    "    densita_text = None\n",
    "    for p in pagina_del_comune.find_all(\"p\"):\n",
    "        if \"Densit√† abitativa\" in p.text:\n",
    "            densita_text = p.text\n",
    "            break\n",
    "\n",
    "    # Estrai il numero dalla stringa trovata\n",
    "    if densita_text:\n",
    "        match = re.search(r\"Densit√† abitativa:\\s*([0-9.,]+)\", densita_text)\n",
    "        if match:\n",
    "            densita = match.group(1)\n",
    "            #print(f\"Densit√† abitativa: {densita} abitanti per km¬≤\")\n",
    "            df_dic['Densit√† abitativa'] = densita\n",
    "        else:\n",
    "            print(\"Densit√† abitativa non trovata.\")\n",
    "    else:\n",
    "        print(\"Sezione sulla densit√† abitativa non trovata.\")\n",
    "    \n",
    "    print(df_dic)\n",
    "    df_comune = pd.DataFrame([df_dic])\n",
    "\n",
    "    # Cerca tutte le <div> che contengono tabelle (le tabelle sono racchiuse in div con classe \"tb_resp\")\n",
    "    div_tables = pagina_del_comune.find_all(\"div\", class_=\"tb_resp\")\n",
    "\n",
    "    families_table = None\n",
    "    for div in div_tables:\n",
    "        table = div.find(\"table\")\n",
    "        if table:\n",
    "            # Verifica se la prima riga (con classe \"info\") contiene \"Numero di componenti\"\n",
    "            header_row = table.find(\"tr\", class_=\"info\")\n",
    "            if header_row:\n",
    "                cells = header_row.find_all(\"td\")\n",
    "                if cells and \"Numero di componenti\" in cells[0].get_text():\n",
    "                    families_table = table\n",
    "                    break\n",
    "\n",
    "    if families_table:\n",
    "        # Estrazione delle righe della tabella\n",
    "        rows = []\n",
    "        for tr in families_table.find_all(\"tr\"):\n",
    "            cols = [td.get_text(strip=True) for td in tr.find_all(\"td\")]\n",
    "            rows.append(cols)\n",
    "        \n",
    "        # La struttura della tabella √® la seguente:\n",
    "        # Prima riga (header): [\"Numero di componenti\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6 o pi√π\"]\n",
    "        # Seconda riga (dati): [\"Numero di famiglie\", \"391\", \"390\", \"244\", \"156\", \"50\", \"32\"]\n",
    "        header = rows[0]\n",
    "        data = rows[1]\n",
    "        \n",
    "        # Creare il DataFrame con la prima riga come intestazione\n",
    "        df = pd.DataFrame([data], columns=header)\n",
    "        df.rename(columns={\"6 o pi√É¬π\": \"6 o pi√π\"}, inplace=True)\n",
    "        \n",
    "        #print(\"Tabella 'Famiglie e loro numerosit√† di componenti':\")\n",
    "        #print(df)\n",
    "        \n",
    "        # Salva il risultato in un file CSV\n",
    "        #df.to_csv(\"famiglie_solarolo.csv\", index=False)\n",
    "    else:\n",
    "        print(\"Tabella 'Famiglie e loro numerosit√† di componenti' non trovata.\")\n",
    "\n",
    "    famiglie = df.drop(columns=[\"Numero di componenti\"])\n",
    "    famiglie[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_famiglie.csv', famiglie)\n",
    "\n",
    "    def table(title):\n",
    "        # Trova il titolo della sezione desiderata\n",
    "        titolo_sezione = pagina_del_comune.find(\"span\", id=\"accatre\", string=title)\n",
    "        # Dati sulla popolazione straniera residente a Solarolo\n",
    "\n",
    "        if titolo_sezione:\n",
    "            # Trova la tabella che segue il titolo della sezione\n",
    "            tabella = titolo_sezione.find_next(\"table\", class_=\"table\")\n",
    "\n",
    "            if tabella:\n",
    "                # Estrai le intestazioni\n",
    "                intestazioni = [th.get_text(strip=True) for th in tabella.find(\"tr\").find_all(\"td\")]\n",
    "\n",
    "                # Estrai i dati della tabella\n",
    "                dati = []\n",
    "                for riga in tabella.find_all(\"tr\")[1:]:  # Ignora la prima riga che contiene le intestazioni\n",
    "                    colonne = [td.get_text(strip=True) for td in riga.find_all(\"td\")]\n",
    "                    dati.append(colonne)\n",
    "\n",
    "                # Creazione del DataFrame\n",
    "                df = pd.DataFrame(dati, columns=intestazioni)\n",
    "                \n",
    "                # Salva il DataFrame in un file CSV\n",
    "                #df.to_csv(\"popolazione_straniera_solarolo.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "                #print(\"File CSV creato con successo: popolazione_straniera_solarolo.csv\")\n",
    "            else:\n",
    "                print(\"Errore: Impossibile trovare la tabella della popolazione straniera.\")\n",
    "        else:\n",
    "            print(\"Errore: Impossibile trovare la sezione 'Dati sulla popolazione straniera residente a Solarolo'.\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    colonne_finali = [\"Settore\", \"Numero_Aziende\", \"Addetti\", \"Percentuale_Totale\"]\n",
    "    settori = pulisci_dataframe(table(\"Geografia, Anagrafe e Statistica\").to_dict(), colonne_finali)\n",
    "    settori[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_settori.csv', settori)\n",
    "\n",
    "\n",
    "    eta = transform_dict_to_df(table(f\"Dati sulla popolazione residente a {comune}\")\n",
    "                        .rename(columns={\"Et√É\": \"Et√†\"})\n",
    "                        .to_dict())\n",
    "    eta[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_et√†.csv', eta)\n",
    "\n",
    "    stranieri = transform_dict_to_df(table(f\"Dati sulla popolazione straniera residente a {comune}\")\n",
    "                        .rename(columns={\"Et√É\": \"Et√†\"})\n",
    "                        .to_dict())\n",
    "\n",
    "    for x in list(stranieri.columns):\n",
    "        nuovo = str(x).replace(\"Pi√É¬π\", \"Pi√π\")\n",
    "        stranieri.rename(columns={x: nuovo}, inplace=True)  # Modifica in-place\n",
    "\n",
    "    stranieri[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_stranieri.csv', stranieri)\n",
    "\n",
    "    scolarizzazione = transform_dict_to_df(table(f\"Livelli di scolarizzazione a {comune}\")\n",
    "                        .to_dict())\n",
    "    scolarizzazione[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_scolarizzazione.csv', scolarizzazione)\n",
    "\n",
    "    def correzione_moneta(valore):\n",
    "        valore = str(valore).replace(\"√¢¬Ç¬¨\", \"‚Ç¨\")\n",
    "        return valore\n",
    "\n",
    "    def table(title):\n",
    "        # Trova il titolo della sezione desiderata\n",
    "        titolo_sezione = pagina_del_comune.find(\"h4\", string=title)\n",
    "\n",
    "        if titolo_sezione:\n",
    "            # Trova la tabella che segue il titolo della sezione\n",
    "            tabella = titolo_sezione.find_next(\"table\", class_=\"table\")\n",
    "\n",
    "            if tabella:\n",
    "                # Estrai le intestazioni\n",
    "                intestazioni = [th.get_text(strip=True) for th in tabella.find(\"tr\").find_all(\"td\")]\n",
    "\n",
    "                # Estrai i dati della tabella\n",
    "                dati = []\n",
    "                for riga in tabella.find_all(\"tr\")[1:]:  # Ignora la prima riga che contiene le intestazioni\n",
    "                    colonne = [td.get_text(strip=True) for td in riga.find_all(\"td\")]\n",
    "                    dati.append(colonne)\n",
    "\n",
    "                # Creazione del DataFrame\n",
    "                df = pd.DataFrame(dati, columns=intestazioni)\n",
    "                df[\"Comune\"] = comune\n",
    "\n",
    "                if \"Reddito\" in df.columns:\n",
    "                    df[\"Reddito\"] = df[\"Reddito\"].apply(correzione_moneta)\n",
    "                    df[\"Media annuale\"] = df[\"Media annuale\"].apply(correzione_moneta)\n",
    "                    df[\"Media mensile\"] = df[\"Media mensile\"].apply(correzione_moneta)\n",
    "                    df[\"Anno precedente\"] = df[\"Anno precedente\"].apply(correzione_moneta)\n",
    "                    df[\"Variazione\"] = df[\"Variazione\"].apply(correzione_moneta)\n",
    "\n",
    "                # Salva il DataFrame in un file CSV\n",
    "                #df.to_csv(\"edifici_solarolo_costruzione.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "                #print(\"File CSV creato con successo: edifici_solarolo_costruzione.csv\")\n",
    "            else:\n",
    "                print(\"Errore: Impossibile trovare la tabella degli edifici per data di costruzione.\")\n",
    "        else:\n",
    "            print(\"Errore: Impossibile trovare la sezione 'Gli edifici a Solarolo per data di costruzione'.\")\n",
    "        \n",
    "        return df\n",
    "\n",
    "    cronologia_edifici = table(f\"Gli edifici a {comune} per data di costruzione\").drop(columns=[\"Date\"])\n",
    "    cronologia_edifici[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_cronologia_edifici.csv', cronologia_edifici)\n",
    "\n",
    "    numero_di_piani = table(f\"Gli edifici a {comune} per numero di piani\").drop(columns=[\"Numero di piani\"])\n",
    "    numero_di_piani.rename(columns={\"Quattro o pi√É¬π\": \"Quattro o pi√π\"}, inplace=True)\n",
    "    numero_di_piani[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_numero_di_piani.csv', numero_di_piani)\n",
    "\n",
    "    interni = table(f\"Gli edifici a {comune} per numero di interni\").drop(columns=[\"Numero di interni\"])\n",
    "    interni[\"Comune\"] = comune\n",
    "    concat_dataframe('inf_interni.csv', interni)\n",
    "\n",
    "    redditi_01 = table(\"Redditi e contribuenti per tipo di reddito\")#.to_csv(\"inf_redditi_01.csv\", index=False)\n",
    "    concat_dataframe('inf_redditi_01.csv', redditi_01)\n",
    "\n",
    "    redditi_02 = table(\"Redditi, imposte e addizionali comunali e regionali\")#.to_csv(\"inf_redditi_02.csv\", index=False)\n",
    "    concat_dataframe('inf_redditi_02.csv', redditi_02)\n",
    "\n",
    "    redditi_03 = table(\"Redditi e contribuenti per fasce di reddito\")#.to_csv(\"inf_redditi_03.csv\", index=False)\n",
    "    concat_dataframe('inf_redditi_03.csv', redditi_03)\n",
    "\n",
    "    # Trova il titolo della sezione con una ricerca flessibile\n",
    "    titolo_sezione = None\n",
    "    for tag in pagina_del_comune.find_all([\"h2\", \"h3\", \"span\", \"p\"]):  # Controlliamo pi√π tag possibili\n",
    "        if re.search(r\"Parrocchie\", tag.get_text(), re.IGNORECASE):\n",
    "            titolo_sezione = tag\n",
    "            break\n",
    "\n",
    "    if titolo_sezione:\n",
    "        # Trova la tabella che segue il titolo della sezione\n",
    "        tabella = titolo_sezione.find_next(\"table\")\n",
    "\n",
    "        if tabella:\n",
    "            # Estrai le intestazioni della tabella\n",
    "            intestazioni = [th.get_text(strip=True) for th in tabella.find(\"tr\").find_all(\"td\")]\n",
    "\n",
    "            # Estrai i dati\n",
    "            dati = []\n",
    "            for riga in tabella.find_all(\"tr\")[1:]:  # Ignora la prima riga che contiene le intestazioni\n",
    "                colonne = [td.get_text(strip=True) for td in riga.find_all(\"td\")]\n",
    "                dati.append(colonne)\n",
    "\n",
    "            # Creazione del DataFrame\n",
    "            parrocchie = pd.DataFrame(dati, columns=intestazioni)\n",
    "\n",
    "            # Salva il DataFrame in un file CSV\n",
    "            #df.to_csv(\"parrocchie_solarolo.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "            #print(\"‚úÖ File CSV creato con successo: parrocchie_solarolo.csv\")\n",
    "        else:\n",
    "            print(\"‚ùå Errore: Impossibile trovare la tabella delle parrocchie.\")\n",
    "    else:\n",
    "        print(\"‚ùå Errore: Non √® stata trovata la sezione 'Parrocchie'.\")\n",
    "    \n",
    "    concat_dataframe('inf_parrocchie.csv', parrocchie)\n",
    "\n",
    "    # Trova la sezione delle scuole\n",
    "    scuole_section = pagina_del_comune.find(\"a\", {\"name\": \"scuole\"})\n",
    "\n",
    "    if scuole_section:\n",
    "        table = scuole_section.find_next(\"table\")  # Trova la tabella successiva\n",
    "\n",
    "        # Estrarre tutte le righe della tabella\n",
    "        rows = []\n",
    "        for tr in table.find_all(\"tr\"):\n",
    "            cells = [td.text.strip() for td in tr.find_all([\"th\", \"td\"])]\n",
    "            rows.append(cells)\n",
    "\n",
    "        # Se la tabella ha almeno una riga, usa la prima come intestazione\n",
    "        if len(rows) > 1:\n",
    "            headers = rows[0]  # Prima riga come intestazione\n",
    "            data = rows[1:]     # Dati senza la prima riga\n",
    "        else:\n",
    "            headers = None\n",
    "            data = rows\n",
    "\n",
    "        # Creare un DataFrame Pandas\n",
    "        scuole = pd.DataFrame(data, columns=headers if headers else None)\n",
    "\n",
    "        # Stampare il risultato\n",
    "        #print(df)\n",
    "    else:\n",
    "        print(\"Tabella delle scuole non trovata.\")\n",
    "    \n",
    "    concat_dataframe('inf_scuole.csv', scuole)\n",
    "\n",
    "    informazioni_geografiche = pd.read_csv(\"informazioni_geografiche.csv\")\n",
    "\n",
    "    data = eta.to_dict()\n",
    "\n",
    "    # Intervalli di et√† e relativi punti medi\n",
    "    age_intervals = {\n",
    "        '0-4': 2, '5-9': 7, '10-14': 12, '15-19': 17, '20-24': 22, '25-29': 27,\n",
    "        '30-34': 32, '35-39': 37, '40-44': 42, '45-49': 47, '50-54': 52, '55-59': 57,\n",
    "        '60-64': 62, '65-69': 67, '70-74': 72, '>74': 77  # Il gruppo \">74\" usa 77 come stima\n",
    "    }\n",
    "\n",
    "    # Calcolare la somma ponderata per la popolazione totale\n",
    "    total_population = 0\n",
    "    weighted_sum = 0\n",
    "\n",
    "    # Calcolare somma ponderata e totale della popolazione\n",
    "    for key, value in data.items():\n",
    "        if 'Totale' in key:  # Consideriamo solo i totali\n",
    "            age_group = key.split('_')[0]  # Estrai il gruppo di et√† (es. '0-4')\n",
    "            middle_age = age_intervals[age_group]  # Et√† media stimata per il gruppo\n",
    "            total_population += int(value[0])  # Converti in intero\n",
    "            weighted_sum += middle_age * int(value[0])  # Aggiungi il contributo ponderato\n",
    "\n",
    "    # Calcolare la media di et√†\n",
    "    average_age = round(weighted_sum / total_population, 2)\n",
    "\n",
    "\n",
    "\n",
    "    # Aggiungi il nome del comune\n",
    "    df_comune[\"Comune\"] = comune\n",
    "    #concat_dataframe('inf_comunali.csv', df_comune)\n",
    "\n",
    "    # Estrai i dati direttamente dalle colonne specifiche\n",
    "    df_comune[\"Regione\"] = informazioni_geografiche[informazioni_geografiche[\"Comune\"] == comune][\"Regione\"].iloc[0]\n",
    "    df_comune[\"Zona\"] = informazioni_geografiche[informazioni_geografiche[\"Comune\"] == comune][\"Macro Zona della Regione\"].iloc[0]\n",
    "    df_comune[\"sigla_provincia\"] = informazioni_geografiche[informazioni_geografiche[\"Comune\"] == comune][\"sigla_provincia\"].iloc[0]\n",
    "    df_comune[\"Et√† (Media)\"] = average_age\n",
    "\n",
    "    # Aggiungi il numero di parrocchie e scuole\n",
    "    df_comune[\"Parrocchie\"] = parrocchie.shape[0]\n",
    "    df_comune[\"Scuole\"] = scuole.shape[0]\n",
    "\n",
    "    # Estrai le percentuali di addetti dai settori\n",
    "    df_comune[\"Industria Addetti\"] = f'{round(settori[settori[\"Settore\"] == \"Industrie\"][\"Percentuale_Totale\"].iloc[0], 2)}%'\n",
    "    df_comune[\"Servizi Addetti\"] = f'{round(settori[settori[\"Settore\"] == \"Servizi\"][\"Percentuale_Totale\"].iloc[0], 2)}%'\n",
    "    df_comune[\"Amministrazione Addetti\"] = f'{round(settori[settori[\"Settore\"] == \"Amministrazione\"][\"Percentuale_Totale\"].iloc[0], 2)}%'\n",
    "    df_comune[\"Altro Addetti\"] = f'{round(settori[settori[\"Settore\"] == \"Altro\"][\"Percentuale_Totale\"].iloc[0], 2)}%'\n",
    "\n",
    "    # Estrai i dati sulla scolarizzazione\n",
    "    df_comune[\"Diplomati\"] = scolarizzazione[scolarizzazione[\"Comune\"] == comune][\"Diploma_Totale\"].iloc[0]\n",
    "    df_comune[\"Laureati\"] = scolarizzazione[scolarizzazione[\"Comune\"] == comune][\"Laurea_Totale\"].iloc[0]\n",
    "    df_comune[\"Liscenziati Midia Totale\"] = scolarizzazione[scolarizzazione[\"Comune\"] == comune][\"Licenza Media_Totale\"].iloc[0]\n",
    "    df_comune[\"Licenza Elementare Totale\"] = scolarizzazione[scolarizzazione[\"Comune\"] == comune][\"Licenza Elementare_Totale\"].iloc[0]\n",
    "    df_comune[\"Alfabeti\"] = scolarizzazione[scolarizzazione[\"Comune\"] == comune][\"Alfabeti_Totale\"].iloc[0]\n",
    "    df_comune[\"Analfabeti\"] = scolarizzazione[scolarizzazione[\"Comune\"] == comune][\"Analfabeti_Totale\"].iloc[0]\n",
    "\n",
    "    # Redditi\n",
    "    df_comune[\"Media annuale (Redditi)\"] = round(redditi_01['Media annuale'].str.replace(\"‚Ç¨\", \"\").str.replace(\".\", \"\")\n",
    "                            .str.replace(\",\", \".\").astype(float).mean(), 2)\n",
    "\n",
    "    df_comune[\"Media Mensile (Redditi)\"] = round(redditi_01['Media mensile'].str.replace(\"‚Ç¨\", \"\").str.replace(\".\", \"\")\n",
    "                            .str.replace(\",\", \".\").astype(float).mean(), 2)\n",
    "\n",
    "    df_comune[\"Imposta netta annuale\"] = float(redditi_02.loc[redditi_02[\"Categoria\"] == \"Imposta netta\", \"Media annuale\"]\n",
    "                                                .iloc[0].replace(\"‚Ç¨\", \"\").replace(\".\", \"\").replace(\",\", \".\").strip())\n",
    "\n",
    "    df_comune[\"Imposta netta mensile\"] = float(redditi_02.loc[redditi_02[\"Categoria\"] == \"Imposta netta\", \"Media mensile\"]\n",
    "                                                .iloc[0].replace(\"‚Ç¨\", \"\").replace(\".\", \"\").replace(\",\", \".\").strip())\n",
    "\n",
    "    # Calcola il totale di stranieri\n",
    "    df_comune[\"Totale di stranieri\"] = (int(stranieri[stranieri[\"Comune\"] == comune]['Totale_Da 0 a 29 anni'].iloc[0]) \n",
    "                                        + int(stranieri[stranieri[\"Comune\"] == comune]['Totale_Da 30 a 54 anni'].iloc[0])\n",
    "                                        + int(stranieri[stranieri[\"Comune\"] == comune]['Totale_Pi√π di 54 anni'].iloc[0]))\n",
    "    \n",
    "    #display(df_comune)\n",
    "    \n",
    "    concat_dataframe('inf_comunali.csv', df_comune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Totale di comuni analizzati: 6133\n",
      "Totale di comuni da analizzare: 1252\n",
      "\n",
      "{'Fiastra': 'Marche', 'Bitetto': 'Puglia', 'Lappano': 'Calabria', 'Castelvetro di Modena': 'Emilia-Romagna', 'Caldonazzo': 'Trentino-Alto Adige', 'Mele': 'Liguria', 'Gavi': 'Piemonte', 'San Pietro Avellana': 'Molise', 'Monsampietro Morico': 'Marche', 'Trana': 'Piemonte', 'Camerota': 'Campania', 'Crevoladossola': 'Piemonte', 'Cortemaggiore': 'Emilia-Romagna', 'Castel del Rio': 'Emilia-Romagna', 'Terricciola': 'Toscana', 'Mirano': 'Veneto', 'Mirandola': 'Emilia-Romagna', 'Campo di Trens': 'Trentino-Alto Adige', 'Albenga': 'Liguria', 'Vernante': 'Piemonte', 'Copparo': 'Emilia-Romagna', 'Sona': 'Veneto', 'Casola in Lunigiana': 'Toscana', 'Francavilla Angitola': 'Calabria', 'Montefelcino': 'Marche', 'Serramazzoni': 'Emilia-Romagna', 'Brennero': 'Trentino-Alto Adige', 'Quiliano': 'Liguria', 'Craco': 'Basilicata', 'Salandra': 'Basilicata', 'Rittana': 'Piemonte', 'Pradleves': 'Piemonte', 'San Leo': 'Emilia-Romagna', 'Garbagna': 'Piemonte', 'Vauda Canavese': 'Piemonte', 'Pratovecchio Stia': 'Toscana', 'Gosaldo': 'Veneto', 'Sanfront': 'Piemonte', 'Trino': 'Piemonte', 'Ronsecco': 'Piemonte', 'Valleve': 'Lombardia', 'Montaguto': 'Campania', 'Contrada': 'Campania', 'San Mauro la Bruca': 'Campania', 'San Mauro Cilento': 'Campania', 'Fino Mornasco': 'Lombardia', 'Opi': 'Abruzzo', 'Morbello': 'Piemonte', 'Cartura': 'Veneto', \"Castel d'Ario\": 'Lombardia'}\n",
      "['Fiastra', 'Bitetto', 'Lappano', 'Castelvetro di Modena', 'Caldonazzo', 'Mele', 'Gavi', 'San Pietro Avellana', 'Monsampietro Morico', 'Trana', 'Camerota', 'Crevoladossola', 'Cortemaggiore', 'Castel del Rio', 'Terricciola', 'Mirano', 'Mirandola', 'Campo di Trens', 'Albenga', 'Vernante', 'Copparo', 'Sona', 'Casola in Lunigiana', 'Francavilla Angitola', 'Montefelcino', 'Serramazzoni', 'Brennero', 'Quiliano', 'Craco', 'Salandra', 'Rittana', 'Pradleves', 'San Leo', 'Garbagna', 'Vauda Canavese', 'Pratovecchio Stia', 'Gosaldo', 'Sanfront', 'Trino', 'Ronsecco', 'Valleve', 'Montaguto', 'Contrada', 'San Mauro la Bruca', 'San Mauro Cilento', 'Fino Mornasco', 'Opi', 'Morbello', 'Cartura', \"Castel d'Ario\"]\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "gia_analizzati = pd.read_csv('inf_comunali.csv')\n",
    "errori = pd.read_csv('Errori.csv')\n",
    "\n",
    "errori_da_rimuovere = list(errori['Comuni'].unique())  # Lista dei comuni unici\n",
    "\n",
    "# Filtra i comuni non ancora analizzati\n",
    "comuni_da_analizzare = informazioni_geografiche[\n",
    "    (~informazioni_geografiche['Comune'].isin(gia_analizzati['Comune'].unique())) &\n",
    "    (~informazioni_geografiche['Comune'].isin(errori_da_rimuovere))\n",
    "]\n",
    "\n",
    "print(f'Totale di comuni analizzati: {len(list(gia_analizzati['Comune'].unique()))}')\n",
    "print(f'Totale di comuni da analizzare: {comuni_da_analizzare.shape[0]}\\n')\n",
    "\n",
    "# Seleziona solo i primi 10\n",
    "comuni_da_analizzare = comuni_da_analizzare.iloc[:50]  # Oppure .head(10)f\n",
    "\n",
    "# Crea il dizionario con il Comune come chiave e la Regione come valore\n",
    "comuni_da_analizzare = dict(zip(comuni_da_analizzare['Comune'], comuni_da_analizzare['Regione']))\n",
    "\n",
    "print(comuni_da_analizzare)\n",
    "print(list(comuni_da_analizzare.keys())[0:60])\n",
    "#print(comuni_da_analizzare[\"L'Aquila\"])\n",
    "print(len(list(comuni_da_analizzare.keys())))\n",
    "\n",
    "#Totale di comuni analizzati: 97 | 6088 6133\n",
    "#Totale di comuni da analizzare: 7805 | 1300 1252\n",
    "# 'San Venanzo', 'Castel Volturno', 'Poggio San Vicino', 'Montemarciano'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comuni_da_analizzare = {\"Solarolo\": \"Emilia-Romagna\"}\n",
    "#comuni_da_analizzare = {\"Solarolo\": \"Emilia-Romagna\", \"Civita\": \"Calabria\", \"Faenza\": \"Emilia-Romagna\", \"Bologna\": \"Emilia-Romagna\", \"Ravenna\": \"Emilia-Romagna\"}\n",
    "#comuni_da_analizzare = {\"L'Aquila\": \"Abruzzo\"}\n",
    "errori_raccolta = []\n",
    "cancella = comuni_da_analizzare\n",
    "\n",
    "import os\n",
    "\n",
    "for comune_dic, regione_dic in comuni_da_analizzare.items():\n",
    "    url_comune = re.sub(r\"[-' ]+\", \"\", comune_dic.lower())\n",
    "    url_regione = re.sub(r\"[-' ]+\", \"\", regione_dic.lower())\n",
    "    url = f'https://italia.indettaglio.it/ita/{url_regione}/{url_comune}.html'\n",
    "    comune = comune_dic\n",
    "\n",
    "    try:\n",
    "        # Inizio del calcolo del tempo\n",
    "        #start_time = time.time()\n",
    "\n",
    "        # Effettua la richiesta HTTP\n",
    "        requisicao = requests.get(url, verify=False, timeout=10)  # Timeout per evitare blocchi infiniti\n",
    "        pagina_del_comune = bs4.BeautifulSoup(requisicao.text, \"html.parser\")\n",
    "\n",
    "        # Calcolo del tempo impiegato\n",
    "        #end_time = time.time()\n",
    "        #elapsed_time = end_time - start_time\n",
    "        #print(f\"‚è±Ô∏è Tempo di richiesta per {comune}: {elapsed_time:.2f} secondi\")\n",
    "    except Exception as e:\n",
    "        print(f\"üö® Errore nella richiesta per {comune}: {e}\")\n",
    "        errori_raccolta.append(comune)  # Salva il comune con errore\n",
    "        continue  # Salta al comune successivo\n",
    "\n",
    "    try:\n",
    "        # Inizio del calcolo del tempo per la raccolta dei dati\n",
    "        #start_time_raccolta = time.time()\n",
    "\n",
    "        # Tenta la raccolta dei dati\n",
    "        raccolta(comune, pagina_del_comune)\n",
    "        informazioni_geografiche.loc[informazioni_geografiche[\"Comune\"] == comune, \"Raccolto\"] = 1\n",
    "        print(f\"‚úÖ {comune} - Raccolta completata\")\n",
    "\n",
    "        # Calcolo del tempo impiegato per la raccolta\n",
    "        #end_time_raccolta = time.time()\n",
    "        #elapsed_time_raccolta = end_time_raccolta - start_time_raccolta\n",
    "        #print(f\"‚è±Ô∏è Tempo di raccolta per {comune}: {elapsed_time_raccolta:.2f} secondi\")\n",
    "    except Exception as e:\n",
    "        informazioni_geografiche.loc[informazioni_geografiche[\"Comune\"] == comune, \"Raccolto\"] = 0\n",
    "        errori_raccolta.append(comune)\n",
    "        print(f\"‚ùå Errore nella funzione RACCOLTA per {comune}: {e}\")\n",
    "        continue\n",
    "\n",
    "    # Assicura il salvataggio del CSV a ogni iterazione\n",
    "    try:\n",
    "        informazioni_geografiche.to_csv(\"informazioni_geografiche.csv\", index=False)\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Errore nel salvataggio del file CSV: {e}\")\n",
    "\n",
    "    time.sleep(0.5)  # Pausa per evitare di sovraccaricare il server\n",
    "\n",
    "# **Gestione del file Errori.csv per aggiungere nuovi errori senza sovrascrivere**\n",
    "errori_path = \"Errori.csv\"\n",
    "\n",
    "# Se esiste gi√†, lo carica, altrimenti crea un DataFrame vuoto\n",
    "if os.path.exists(errori_path):\n",
    "    errori_esistenti = pd.read_csv(errori_path)\n",
    "else:\n",
    "    errori_esistenti = pd.DataFrame(columns=[\"Comuni\"])  # Usa \"Comuni\" come nome di colonna\n",
    "\n",
    "# Crea DataFrame con i nuovi errori\n",
    "errori_raccolta_df = pd.DataFrame({\"Comuni\": errori_raccolta})\n",
    "\n",
    "# Unisce i nuovi errori con quelli esistenti\n",
    "errori_totali = pd.concat([errori_esistenti, errori_raccolta_df], ignore_index=True)\n",
    "\n",
    "# Rimuove duplicati\n",
    "errori_totali = errori_totali.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "# Salva il file aggiornato con il nome corretto della colonna\n",
    "errori_totali.to_csv(errori_path, index=False)\n",
    "\n",
    "print(\"\\nüîÑ File Errori.csv aggiornato correttamente senza duplicare colonne.\")\n",
    "#playsound(\"Successo.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(comuni_da_analizzare.keys())[7:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comune_dic = 'Barletta-Andria-Trani'\n",
    "re.sub(r\"[-' ]+\", \"\", comune_dic.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_comunali = pd.read_csv(\"inf_comunali.csv\")\n",
    "#inf_comunali.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_comunali[inf_comunali[\"Comune\"] == \"Fragagnano\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cancellare le righe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['Bitetto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n",
      "C:\\Users\\schit\\AppData\\Local\\Temp\\ipykernel_46200\\3639449420.py:8: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(x)\n"
     ]
    }
   ],
   "source": [
    "def cancellare():\n",
    "    for comune in list(cancella.keys()):\n",
    "        list_dfs = ['inf_comunali.csv', 'inf_cronologia_edifici.csv', 'inf_et√†.csv', 'inf_famiglie.csv', 'inf_interni.csv', 'inf_numero_di_piani.csv',\n",
    "                    'inf_parrocchie.csv', 'inf_redditi_01.csv', 'inf_redditi_02.csv', 'inf_redditi_03.csv', 'inf_scolarizzazione.csv', 'inf_scuole.csv',\n",
    "                    'inf_settori.csv', 'inf_stranieri.csv']\n",
    "\n",
    "        for x in list_dfs:\n",
    "            df = pd.read_csv(x)\n",
    "            df = df.drop(df[df['Comune'] == comune].index)\n",
    "            df.to_csv(x, index=False)\n",
    "        \n",
    "            informazioni_geografiche.loc[informazioni_geografiche[\"Comune\"] == comune, \"Raccolto\"] = 0\n",
    "            informazioni_geografiche.to_csv(\"informazioni_geografiche.csv\", index=False)\n",
    "\n",
    "#cancellare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "province_regioni = {\n",
    "    \"Agrigento\": \"Sicilia\",\n",
    "    \"Alessandria\": \"Piemonte\",\n",
    "    \"Ancona\": \"Marche\",\n",
    "    \"Aosta\": \"Valle d'Aosta\",\n",
    "    \"Arezzo\": \"Toscana\",\n",
    "    \"Ascoli Piceno\": \"Marche\",\n",
    "    \"Asti\": \"Piemonte\",\n",
    "    \"Avellino\": \"Campania\",\n",
    "    \"Bari\": \"Puglia\",\n",
    "    \"Barletta-Andria-Trani\": \"Puglia\",\n",
    "    \"Belluno\": \"Veneto\",\n",
    "    \"Benevento\": \"Campania\",\n",
    "    \"Bergamo\": \"Lombardia\",\n",
    "    \"Biella\": \"Piemonte\",\n",
    "    \"Bologna\": \"Emilia-Romagna\",\n",
    "    \"Bolzano\": \"Trentino-Alto Adige\",\n",
    "    \"Brescia\": \"Lombardia\",\n",
    "    \"Brindisi\": \"Puglia\",\n",
    "    \"Cagliari\": \"Sardegna\",\n",
    "    \"Caltanissetta\": \"Sicilia\",\n",
    "    \"Campobasso\": \"Molise\",\n",
    "    \"Caserta\": \"Campania\",\n",
    "    \"Catania\": \"Sicilia\",\n",
    "    \"Catanzaro\": \"Calabria\",\n",
    "    \"Chieti\": \"Abruzzo\",\n",
    "    \"Como\": \"Lombardia\",\n",
    "    \"Cosenza\": \"Calabria\",\n",
    "    \"Cremona\": \"Lombardia\",\n",
    "    \"Crotone\": \"Calabria\",\n",
    "    \"Cuneo\": \"Piemonte\",\n",
    "    \"Enna\": \"Sicilia\",\n",
    "    \"Fermo\": \"Marche\",\n",
    "    \"Ferrara\": \"Emilia-Romagna\",\n",
    "    \"Firenze\": \"Toscana\",\n",
    "    \"Foggia\": \"Puglia\",\n",
    "    \"Forl√¨-Cesena\": \"Emilia-Romagna\",\n",
    "    \"Frosinone\": \"Lazio\",\n",
    "    \"Genova\": \"Liguria\",\n",
    "    \"Gorizia\": \"Friuli Venezia Giulia\",\n",
    "    \"Grosseto\": \"Toscana\",\n",
    "    \"Imperia\": \"Liguria\",\n",
    "    \"Isernia\": \"Molise\",\n",
    "    \"L'Aquila\": \"Abruzzo\",\n",
    "    \"La Spezia\": \"Liguria\",\n",
    "    \"Latina\": \"Lazio\",\n",
    "    \"Lecce\": \"Puglia\",\n",
    "    \"Lecco\": \"Lombardia\",\n",
    "    \"Livorno\": \"Toscana\",\n",
    "    \"Lodi\": \"Lombardia\",\n",
    "    \"Lucca\": \"Toscana\",\n",
    "    \"Macerata\": \"Marche\",\n",
    "    \"Mantova\": \"Lombardia\",\n",
    "    \"Massa-Carrara\": \"Toscana\",\n",
    "    \"Matera\": \"Basilicata\",\n",
    "    \"Messina\": \"Sicilia\",\n",
    "    \"Milano\": \"Lombardia\",\n",
    "    \"Modena\": \"Emilia-Romagna\",\n",
    "    \"Monza e della Brianza\": \"Lombardia\",\n",
    "    \"Napoli\": \"Campania\",\n",
    "    \"Novara\": \"Piemonte\",\n",
    "    \"Nuoro\": \"Sardegna\",\n",
    "    \"Oristano\": \"Sardegna\",\n",
    "    \"Padova\": \"Veneto\",\n",
    "    \"Palermo\": \"Sicilia\",\n",
    "    \"Parma\": \"Emilia-Romagna\",\n",
    "    \"Pavia\": \"Lombardia\",\n",
    "    \"Perugia\": \"Umbria\",\n",
    "    \"Pesaro e Urbino\": \"Marche\",\n",
    "    \"Pescara\": \"Abruzzo\",\n",
    "    \"Piacenza\": \"Emilia-Romagna\",\n",
    "    \"Pisa\": \"Toscana\",\n",
    "    \"Pistoia\": \"Toscana\",\n",
    "    \"Pordenone\": \"Friuli Venezia Giulia\",\n",
    "    \"Potenza\": \"Basilicata\",\n",
    "    \"Prato\": \"Toscana\",\n",
    "    \"Ragusa\": \"Sicilia\",\n",
    "    \"Ravenna\": \"Emilia-Romagna\",\n",
    "    \"Reggio Calabria\": \"Calabria\",\n",
    "    \"Reggio Emilia\": \"Emilia-Romagna\",\n",
    "    \"Rieti\": \"Lazio\",\n",
    "    \"Rimini\": \"Emilia-Romagna\",\n",
    "    \"Roma\": \"Lazio\",\n",
    "    \"Rovigo\": \"Veneto\",\n",
    "    \"Salerno\": \"Campania\",\n",
    "    \"Sassari\": \"Sardegna\",\n",
    "    \"Savona\": \"Liguria\",\n",
    "    \"Siena\": \"Toscana\",\n",
    "    \"Siracusa\": \"Sicilia\",\n",
    "    \"Sondrio\": \"Lombardia\",\n",
    "    \"Sud Sardegna\": \"Sardegna\",\n",
    "    \"Taranto\": \"Puglia\",\n",
    "    \"Teramo\": \"Abruzzo\",\n",
    "    \"Terni\": \"Umbria\",\n",
    "    \"Torino\": \"Piemonte\",\n",
    "    \"Trapani\": \"Sicilia\",\n",
    "    \"Trento\": \"Trentino-Alto Adige\",\n",
    "    \"Treviso\": \"Veneto\",\n",
    "    \"Trieste\": \"Friuli Venezia Giulia\",\n",
    "    \"Udine\": \"Friuli Venezia Giulia\",\n",
    "    \"Varese\": \"Lombardia\",\n",
    "    \"Venezia\": \"Veneto\",\n",
    "    \"Verbano-Cusio-Ossola\": \"Piemonte\",\n",
    "    \"Vercelli\": \"Piemonte\",\n",
    "    \"Verona\": \"Veneto\",\n",
    "    \"Vibo Valentia\": \"Calabria\",\n",
    "    \"Vicenza\": \"Veneto\",\n",
    "    \"Viterbo\": \"Lazio\"\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
